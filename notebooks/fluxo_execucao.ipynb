{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fluxo de Execução da Aplicação (Pipeline Padrão)\n",
    "\n",
    "Este notebook descreve o fluxo de execução padrão da aplicação Kedro, conforme definido em `pipeline_registry.py`. O pipeline `__default__` executa as seguintes etapas principais em sequência:\n",
    "\n",
    "1.  **Pipeline de Processamento de Dados (`data_processing`)**: Prepara os dados brutos para modelagem.\n",
    "2.  **Pipeline de Ciência de Dados (`data_science`)**: Treina modelos e seleciona o melhor.\n",
    "3.  **Pipeline de Relatórios (`reporting`)**: Gera visualizações e relatórios sobre os modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pipeline de Processamento de Dados (`data_processing`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este pipeline é responsável por carregar, limpar, transformar e dividir os dados.\n",
    "\n",
    "**Passos:**\n",
    "\n",
    "1.  **`preprocess_shuttles_node`**: \n",
    "    - **Função:** `preprocess_shuttles`\n",
    "    - **Entradas:** `dataset_dev`, `dataset_prod`\n",
    "    - **Saída:** `shuttles_filtered`\n",
    "    - **Descrição:** Pré-processa os datasets de desenvolvimento e produção.\n",
    "\n",
    "2.  **`save_filtered_data_node`**: \n",
    "    - **Função:** `save_filtered_data`\n",
    "    - **Entrada:** `shuttles_filtered`\n",
    "    - **Saída:** `data_filtered`\n",
    "    - **Descrição:** Salva os dados pré-processados.\n",
    "\n",
    "3.  **`split_data_node`**: \n",
    "    - **Função:** `split_data`\n",
    "    - **Entrada:** `data_filtered`\n",
    "    - **Saídas:** `train_data`, `test_data`\n",
    "    - **Descrição:** Divide os dados em conjuntos de treino e teste.\n",
    "\n",
    "4.  **`save_train_data_node`**: \n",
    "    - **Função:** `save_filtered_data`\n",
    "    - **Entrada:** `train_data`\n",
    "    - **Saída:** `base_train`\n",
    "    - **Descrição:** Salva o conjunto de dados de treino.\n",
    "\n",
    "5.  **`save_test_data_node`**: \n",
    "    - **Função:** `save_filtered_data`\n",
    "    - **Entrada:** `test_data`\n",
    "    - **Saída:** `base_test`\n",
    "    - **Descrição:** Salva o conjunto de dados de teste.\n",
    "\n",
    "6.  **`create_model_input_table_node`**: \n",
    "    - **Função:** `create_model_input_table`\n",
    "    - **Entrada:** `base_train`\n",
    "    - **Saída:** `model_input_table`\n",
    "    - **Descrição:** Cria a tabela final para entrada no modelo (usando apenas dados de treino).\n",
    "\n",
    "7.  **`preprocess_prod_data_node`**: \n",
    "    - **Função:** `preprocess_single_dataset`\n",
    "    - **Entrada:** `dataset_prod`\n",
    "    - **Saída:** `preprocessed_prod_data`\n",
    "    - **Descrição:** Pré-processa o dataset de produção separadamente (potencialmente para inferência ou monitoramento)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pipeline de Ciência de Dados (`data_science`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este pipeline treina diferentes modelos de classificação, avalia-os e seleciona o melhor.\n",
    "\n",
    "**Passos:**\n",
    "\n",
    "1.  **`train_lr_node`**: \n",
    "    - **Função:** `train_logistic_regression`\n",
    "    - **Entradas:** `base_train`, `base_test`\n",
    "    - **Saída:** `lr_model`\n",
    "    - **Descrição:** Treina um modelo de Regressão Logística.\n",
    "\n",
    "2.  **`train_dt_node`**: \n",
    "    - **Função:** `train_decision_tree`\n",
    "    - **Entradas:** `base_train`, `base_test`\n",
    "    - **Saída:** `dt_model`\n",
    "    - **Descrição:** Treina um modelo de Árvore de Decisão.\n",
    "\n",
    "3.  **`select_best_model_node`**: \n",
    "    - **Função:** `select_best_model`\n",
    "    - **Entradas:** `lr_model`, `dt_model`, `base_test`\n",
    "    - **Saídas:** `final_model`, `best_model_justification_string`, `lr_f1_metric`, `lr_logloss_metric`, `dt_f1_metric`, `dt_logloss_metric`\n",
    "    - **Descrição:** Compara os modelos treinados usando os dados de teste (`base_test`), seleciona o melhor (`final_model`), calcula métricas (F1-score, LogLoss) e gera uma justificativa (`best_model_justification_string`).\n",
    "\n",
    "4.  **`save_model_justification_node`**: \n",
    "    - **Função:** `save_model_justification`\n",
    "    - **Entrada:** `best_model_justification_string`\n",
    "    - **Saída:** `model_justification`\n",
    "    - **Descrição:** Salva a justificativa da seleção do modelo em um arquivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pipeline de Relatórios (`reporting`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este pipeline gera saídas visuais para análise dos resultados.\n",
    "\n",
    "**Passos:**\n",
    "\n",
    "1.  **`plot_model_metrics_node`**: \n",
    "    - **Função:** `plot_model_comparison_metrics`\n",
    "    - **Entradas:** `lr_f1_metric`, `lr_logloss_metric`, `dt_f1_metric`, `dt_logloss_metric`\n",
    "    - **Saída:** `model_comparison_metrics_plot`\n",
    "    - **Descrição:** Cria um gráfico comparando as métricas F1 e LogLoss dos modelos treinados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "O fluxo padrão automatiza o processo desde a preparação dos dados até o treinamento, seleção e visualização de métricas dos modelos, garantindo um ciclo de desenvolvimento MLOps reprodutível."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
